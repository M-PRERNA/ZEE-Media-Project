{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4059bff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e9c714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import speech_recognition as sr \n",
    "import os \n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import moviepy.editor as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9de5d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac31ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a2bf826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "849473ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that splits the audio file into chunks\n",
    "# and applies speech recognition\n",
    "def get_large_audio_transcription(path):\n",
    "    \"\"\"\n",
    "    Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\n",
    "    \"\"\"\n",
    "    r = sr.Recognizer()\n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_wav(path)  \n",
    "    # split audio sound where silence is 500 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,\n",
    "        # experiment with this value for your target audio file\n",
    "        min_silence_len = 500,\n",
    "        # adjust this per requirement\n",
    "        silence_thresh = sound.dBFS-14,\n",
    "        # keep the silence for 1 second, adjustable as well\n",
    "        keep_silence=500,\n",
    "    )\n",
    "    folder_name = \"audio-chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "    # process each chunk \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        # recognize the chunk\n",
    "        with sr.AudioFile(chunk_filename) as source:\n",
    "            audio_listened = r.record(source)\n",
    "            # try converting it to text\n",
    "            try:\n",
    "                text = r.recognize_google(audio_listened)\n",
    "            except sr.UnknownValueError as e:\n",
    "                print(\"Error:\", str(e))\n",
    "            else:\n",
    "                text = f\"{text.capitalize()}. \"\n",
    "                print(chunk_filename, \":\", text)\n",
    "                whole_text += text\n",
    "    # return the text for all chunks detected\n",
    "    return whole_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdff9307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step1(video):\n",
    "    clip = mp.VideoFileClip(r\"rahul.3gpp\")\n",
    "    clip.audio.write_audiofile(r\"converted.wav\")\n",
    "    # create a speech recognition object\n",
    "#     r = sr.Recognizer()\n",
    "    path = \"converted.wav\"\n",
    "    socket.getaddrinfo('localhost', 8080)\n",
    "    text = get_large_audio_transcription(path)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24a88a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step2(t):\n",
    "    model = TFAutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "# T5 uses a max_length of 512 so we cut the article to 512 tokens.\n",
    "    inputs = tokenizer(\"summarize: \" + t, return_tensors=\"tf\", max_length=512, truncation=True)\n",
    "    outputs = model.generate(\n",
    "        inputs['input_ids'], max_length=150, min_length=100, length_penalty=5.0, num_beams=4,early_stopping=True \n",
    "    )\n",
    "    summary = tokenizer.decode(outputs[0])\n",
    "    print(summary)\n",
    "    \n",
    "    str(tokenizer.decode(outputs[0]))\n",
    "    \n",
    "    displacy.render(nlp(str(t)), jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e3d29b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def step3(t):\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "#     model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "#     nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "#     ner_results = nlp(t)\n",
    "#     print(ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bf40baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "step1_transformer = FunctionTransformer(step1)\n",
    "step2_transformer = FunctionTransformer(step2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26be7801",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('step1' , step1_transformer),\n",
    "    ('step2',step2_transformer)])\n",
    "# pipe_transform = pipe.fit_transform('rahul.3gpp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78228f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text1 = step1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8602e227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# text2 = step2(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f5ae43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c4c1d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in converted.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Error: \n",
      "audio-chunks\\chunk2.wav : How to be principal. \n",
      "audio-chunks\\chunk3.wav : Only. \n",
      "audio-chunks\\chunk4.wav : Million ways to be fixed. \n",
      "audio-chunks\\chunk5.wav : Each one of us has to find our own path. \n",
      "audio-chunks\\chunk6.wav : Cute picture of boy born in a typical middle class family. \n",
      "audio-chunks\\chunk7.wav : Who is that boy. \n",
      "audio-chunks\\chunk8.wav : Some points in the early years. \n",
      "audio-chunks\\chunk9.wav : Find me what are you doing want to do. \n",
      "audio-chunks\\chunk10.wav : Telling myself in the household was no accident the first is a. \n",
      "audio-chunks\\chunk11.wav : I know that sometimes inspiration disturb you in the face. \n",
      "audio-chunks\\chunk12.wav : School days. \n",
      "audio-chunks\\chunk13.wav : How is getting more into my own world of cricket. \n",
      "audio-chunks\\chunk14.wav : Winning went to school tournament held back winning the world cup. \n",
      "audio-chunks\\chunk15.wav : School taking for my greatest mission. \n",
      "audio-chunks\\chunk16.wav : Alone sometimes it comes from the most unexpected places and it can make all the difference. \n",
      "Error: \n",
      "Error: \n",
      "audio-chunks\\chunk19.wav : My own reason to support along the way. \n",
      "audio-chunks\\chunk20.wav : Principal orders. \n",
      "audio-chunks\\chunk21.wav : Despite not company musically that might help me build on our future alone with my pics understand my girlfriend. \n",
      "audio-chunks\\chunk22.wav : Find everything to me and i ask myself you. \n",
      "audio-chunks\\chunk23.wav : My mum is to remain focused on my eyes on the definition of it and it was then that i realise that you don't have to be number one in the world you just have to be number one yourself reaching that it is the highest peak lyrics. \n",
      "audio-chunks\\chunk24.wav : Let the mountain climber and answers in the next mountain to climb on 7th august. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large-cnn.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s><s>School taking for my greatest mission. My own reason to support along the way. Despite not company musically that might help me build on our future alone with my girlfriend. My mum is to remain focused on my eyes on the definition of it and it was then that i realise that you don't have to be number one in the world you just have tobe number one yourself reaching that it is the highest peak. Let the mountain climber and answers in the next mountain to climb on 7th august.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">How to be principal. Only. Million ways to be fixed. Each one of us has to find our own path. Cute picture of boy born in a typical middle class family. Who is that boy. Some points in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the early years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". Find me what are you doing want to do. Telling myself in the household was no accident the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " is a. I know that sometimes inspiration disturb you in the face. School days. How is getting more into my own world of cricket. Winning went to school tournament held back winning \n",
       "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the world cup\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
       "</mark>\n",
       ". School taking for my greatest mission. Alone sometimes it comes from the most unexpected places and it can make all the difference. My own reason to support along the way. Principal orders. Despite not company musically that might help me build on our future alone with my pics understand my girlfriend. Find everything to me and i ask myself you. My mum is to remain focused on my eyes on the definition of it and it was then that i realise that you don't have to be number \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " in the world you just have to be number one yourself reaching that it is the highest peak lyrics. Let the mountain climber and answers in the next mountain to climb on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    7th august\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe.fit_transform('rahul.3gpp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c34e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c146a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
